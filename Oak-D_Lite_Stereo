# press q to end the program
# Currently the display is shifted to the left but the numbers line up with the camera
import cv2
import depthai as dai
import numpy as np

# returns Frames in form openCV can display
def getFrame(queue):
    frame = queue.get()
    return frame.getCvFrame()

def getMonoCamera(pipeline, isleft):
    # Configure Mono Camera(Individual Cameras)
    mono = pipeline.createMonoCamera()
    
    #Set Camera Resolution
    mono.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)

    if isleft:
        #CAM_B is the left camera
        mono.setBoardSocket(dai.CameraBoardSocket.CAM_B)
    else : 
        #CAM_C is the right camera
        mono.setBoardSocket(dai.CameraBoardSocket.CAM_C)
    return mono

def getStereoPair(pipeline, monoLeft, monoRight):
    # Sets up the Stereo Node
    stereo = pipeline.create(dai.node.StereoDepth)
    
    # Sets the confidence of the AI. 200 recomended 
    # Higher values makes it more acurate but gives less data(more blank spots)
    stereo.initialConfig.setConfidenceThreshold(200)
    # Checks the Image both from left to right and right to left then compares them. improves accuracy
    stereo.setLeftRightCheck(True)
    # Increases the range of the disparity search. makes it better at detecting close things
    stereo.setExtendedDisparity(True)
    # Filter to help smoothout the data and fill in gaps
    stereo.setMedianFilter(dai.MedianFilter.KERNEL_7x7)
    # Does more depth steps. helps for long distances and Surface Normals. 
    # is disabled when Median filter is used at higher values
    stereo.setSubpixel(False)

    monoLeft.out.link(stereo.left)
    monoRight.out.link(stereo.right)

    return stereo

if __name__ == '__main__':

    # Create pipeline
    pipeline = dai.Pipeline()

    # Set up left and right Cameras
    monoLeft = getMonoCamera(pipeline, isleft= True)
    monoRight = getMonoCamera(pipeline, isleft= False)

    # Combine left and right cameras
    stereo = getStereoPair(pipeline, monoLeft, monoRight)

    # Set up XLink for Stereo Camera disparity
    xoutDisp = pipeline.createXLinkOut()
    xoutDisp.setStreamName("disparity")

    # Set up XLink for Stereo Camera Depth
    xoutDepth = pipeline.createXLinkOut()
    xoutDepth.setStreamName("depth")

    stereo.depth.link(xoutDepth.input)
    stereo.disparity.link(xoutDisp.input)

    # Corrects for unknown distance Static
    preDepth = 0

    # Pipeline is defined
    with dai.Device(pipeline) as device:

        # Get output queues
        disparityQueue = device.getOutputQueue(name = "disparity", maxSize = 2, blocking = False)
        depthQueue = device.getOutputQueue(name = "depth", maxSize = 2, blocking = False)

        # Calculate the colormap
        disparityMultiplier = 255 / stereo.initialConfig.getMaxDisparity()
        depthMultiplier = 255 / 1000

        while True:
            # Get frames in cv2 format
            disparity = getFrame(disparityQueue)
            depth = getFrame(depthQueue)
            # Get frames for depth values
            dep = depthQueue.get()
            depthFrame = dep.getFrame()

            # ColorMap for view
            disparity = (disparity * disparityMultiplier).astype(np.uint8)
            disparity = cv2.applyColorMap(disparity, cv2.COLORMAP_JET)
            depth = (depth * depthMultiplier).astype(np.uint8)
            depth = cv2.applyColorMap(depth, cv2.COLORMAP_JET)

            # Finds the size and center of the display
            height, width = depthFrame.shape
            centerX, centerY = width // 2, height // 2

            # Find the distance at the center. any value works
            distance = depthFrame[centerX + 10,centerY]

            # Sets distance as previous output if 
            if distance <= 1:
                distance = preDepth

            # Creates a dot and displays the distance
            imOut = cv2.circle(depth, (centerX, centerY), 2, (0, 0, 100), -1)
            imOut = cv2.putText(depth, str(distance) + "mm" , (centerX + 3, centerY), 
                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 100,), 3)
            
            # Displays Screens
            cv2.imshow("Disparity", disparity)
            cv2.imshow("Depth", depth)

            preDepth = distance
            # Ends Stream when q is pressed
            key = cv2.waitKey(1)
            if key == ord('q'):
                break

